# 参考阅读

| Title                                        | URL                                                          | 备注                                                         |
| -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 为什么用交叉熵做损失函数？                   | [link](https://zhuanlan.zhihu.com/p/70804197)                | 分类一般使用交叉熵作为损失函数                               |
| 机器学习准则（期望风险、经验风险、结构风险） | [link](https://zhuanlan.zhihu.com/p/159189617)               | 期望风险不可知，故用经验风险近似                             |
| 【直观详解】什么是正则化                     | [link](https://charlesliuyx.github.io/2017/10/03/%E3%80%90%E7%9B%B4%E8%A7%82%E8%AF%A6%E8%A7%A3%E3%80%91%E4%BB%80%E4%B9%88%E6%98%AF%E6%AD%A3%E5%88%99%E5%8C%96/) | 正则化用以防止模型过拟合                                     |
| 特征提取                                     | [link](https://baike.baidu.com/item/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/8827539) | 举一个例子来表示我对特征选择和特征提取的理解： 现已有淘宝店的4个特征量为：下单量，浏览量，店内物品总数，淘宝店主名字。想要的预测结果是成交量。 1.特征选择，删除对预测结果没有什么影响的特征量，例如此处淘宝店主名字基本与成交量无关，删去，得到3个特征量。这就是特征选择的作用，选取较优的子集。 2.特征提取，用最常见的pca方法（主成成分分析）来看，在剩下的3个特征量中，基本每一个都会影响成交量，但是特征量之间有没有什么联系呢？通常来说，如果某个店铺的浏览量很大，那么下单量也会有相应的增长，举个极端的例子，如果某店铺浏览量为0，则下单量基本也为0，那么在这两个特征量相关性较大的情况下，我们采取一定的办法看是否能够删除某一特征量，或者看能否进行变换/合并来表示这两个特征量。假设这里我们定义一个新的特征量为：下单浏览量=下单量*浏览量（随便列的公式），那么该模型最后只剩下2个特征量。也就是说，特征提取主要是解决或减少特征量之间的相关性，也是会涉及到降维的过程的。 |

